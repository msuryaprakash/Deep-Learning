{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    \n",
    "    #############################################################################################\n",
    "    #INPUTS: learning_rate - how big step to perform in convex optimization\n",
    "    #        epochs - how many times trainging of neural network will be performed\n",
    "    #        reg - regularization constant\n",
    "    #        init - way that weights will be initialized (default value is random)\n",
    "    #        update - technique that will be used to update weights and biases\n",
    "    #        momentum - this parameter is used just in momentum type of update - (velocity = 0)\n",
    "    #        activation - which activation function will be used on HIDDEN layers\n",
    "    #        dropout - (normal value = 0.5) if it's 0, dropout won't be performed\n",
    "    #        random_init - setting seed for random \n",
    "    #############################################################################################\n",
    "    def __init__(self, learning_rate=0.01, reg=0.1, epochs=10001, init='he_et', activation='relu', update='SGD', verbose=False, momentum=0.9, dropout=0, random_init=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg = reg\n",
    "        self.epochs = epochs\n",
    "        self.init = init\n",
    "        self.verbose = verbose\n",
    "        self.update = update\n",
    "        self.momentum = momentum\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "#         np.random.seed(random_init)\n",
    "        \n",
    "    #ACTIVATION FUNCTIONS - FORWARD_PROP###############################################\n",
    "    def softmax(self, x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def leaky_relu(self, x, alpha=0.01):\n",
    "        return np.maximum(alpha * x, x)\n",
    "   \n",
    "    ####################################################################################\n",
    "    \n",
    "    #ACTIVATION FUNCTIONS - BACK_PROP###################################################\n",
    "    def sigmoid_der(self, x):\n",
    "        return (1 - x) * x\n",
    "    \n",
    "    def relu_der(self, x):\n",
    "        return 1. * (x > 0)\n",
    "    \n",
    "    def tanh_der(self, x):\n",
    "        return 1.0 - np.tanh(x)**2\n",
    "   \n",
    "    def leaky_relu_der(self, x, alpha=0.01):\n",
    "        gradients = 1. * (x > 0)\n",
    "        gradients[gradients == 0] = alpha\n",
    "        return gradients  \n",
    "    #####################################################################################\n",
    "    \n",
    "    #LOSS FUNCTION#######################################################################\n",
    "    #INPUT: x - outputs from neural network\n",
    "    #       no_of_samples - numbers of samples in training set\n",
    "    #       y - training labels\n",
    "    #\n",
    "    #OUTPUT: loss/error for current epoche\n",
    "    def softmax_loss(self, x, no_of_samples, y):\n",
    "        logs = -np.log(x[range(no_of_samples), y])\n",
    "        data_loss = np.sum(logs)/no_of_samples\n",
    "        reg_loss = 0.5*self.reg * np.sum(self.W1*self.W1) + 0.5*self.reg*np.sum(self.W2*self.W2)\n",
    "        loss = data_loss + reg_loss\n",
    "        return loss\n",
    "    ######################################################################################\n",
    "    \n",
    "    #TRAIN NEURAL NETWORK#################################################################\n",
    "    #INPUT: X - training features\n",
    "    #       y - training labels\n",
    "    #\n",
    "    #OUTPUT: loss_history - list of losses per epoche\n",
    "    def train(self, X, y):\n",
    "        \n",
    "        #ADITIONAL VARIABLES##################\n",
    "        self.y_train = y.reshape(y.shape[0],1)\n",
    "        loss_history = []\n",
    "        #for momentum update\n",
    "        vW1 = 0\n",
    "        vb1 = 0\n",
    "        vW2 = 0\n",
    "        vb2 = 0\n",
    "        vW3 = 0\n",
    "        vb3 = 0\n",
    "        ######################################\n",
    "        \n",
    "        #WEIGHTS INIT#######################################################\n",
    "        if self.init == 'random':\n",
    "            self.W1 = np.random.randn(X.shape[1], 6)\n",
    "            self.b1 = np.zeros(6) / np.sqrt(6)\n",
    "            self.W2 = np.random.randn(6, 6)\n",
    "            self.b2 = np.zeros(6)\n",
    "            self.W3 = np.random.randn(6, 1)\n",
    "            self.b3 = np.zeros(1)\n",
    "       \n",
    "        elif self.init == 'xavier':\n",
    "            self.W1 = np.random.randn(X.shape[1], 6) / np.sqrt(X.shape[1])\n",
    "            self.b1 = np.zeros(6) / np.sqrt(6)\n",
    "            self.W2 = np.random.randn(6, 6) / np.sqrt(X.shape[1])\n",
    "            self.b2 = np.zeros(6) / np.sqrt(6)\n",
    "            self.W3 = np.random.randn(6, 1) / np.sqrt(6)\n",
    "            self.b3 = np.zeros(1) / np.sqrt(1)\n",
    "        \n",
    "        elif self.init == 'he_et':\n",
    "            self.W1 = np.random.randn(X.shape[1], 6) / np.sqrt(2.0/X.shape[1])\n",
    "            self.b1 = np.zeros(6) / np.sqrt(2.0/6)\n",
    "            self.W2 = np.random.randn(6, 6) / np.sqrt(2.0/X.shape[1])\n",
    "            self.b2 = np.zeros(6) / np.sqrt(2.0/6)\n",
    "            self.W3 = np.random.randn(6, 1) / np.sqrt(2.0/6)\n",
    "            self.b3 = np.zeros(1) / np.sqrt(2.0/1)\n",
    "        ######################################################################\n",
    "       \n",
    "        #Training loop\n",
    "        for i in range(self.epochs):\n",
    "            l1, l2, scores = self.forward_prop(X)\n",
    "            \n",
    "            #ERROR FOR BINARY CLASS\n",
    "            scores_error = self.y_train - scores\n",
    "            loss_history.append(np.mean(np.abs(scores_error)))\n",
    "            \n",
    "            #NOTE FOR ERROR: for more classes user softmax_loss to calculate loss\n",
    "            \n",
    "            #VIZUALIZATION PART: \n",
    "            if self.verbose == True:\n",
    "                if i % 1000 == 0:\n",
    "                    print(\"Epoche: \", i , \"Loss: \", np.mean(np.abs(scores_error)))\n",
    "             \n",
    "            #BACKPROP######################################\n",
    "            if self.activation == 'relu':\n",
    "                scores_delta = scores_error*self.sigmoid_der(scores)\n",
    "                l2_error = scores_delta.dot(self.W3.T)\n",
    "                l2_delta = l2_error*self.relu_der(l2)\n",
    "                l1_error = l2_delta.dot(self.W2.T)\n",
    "                l1_delta = l1_error*self.relu_der(l1)\n",
    "            \n",
    "            elif self.activation == 'sigmoid':\n",
    "                scores_delta = scores_error*self.sigmoid_der(scores)\n",
    "                l2_error = scores_delta.dot(self.W3.T)\n",
    "                l2_delta = l2_error*self.sigmoid_der(l2)\n",
    "                l1_error = l2_delta.dot(self.W2.T)\n",
    "                l1_delta = l1_error*self.sigmoid_der(l1)\n",
    "                \n",
    "            elif self.activation == 'tanh':\n",
    "                scores_delta = scores_error * self.sigmoid_der(scores)\n",
    "                l2_error = scores_delta.dot(self.W3.T)\n",
    "                l2_delta = l2_error * self.tanh_der(l2)\n",
    "                l1_error = l2_delta.dot(self.W2.T)\n",
    "                l1_delta = l1_error * self.tanh_der(l1)\n",
    "                \n",
    "            elif self.activation == 'leaky_relu':\n",
    "                scores_delta = scores_error * self.sigmoid_der(scores)\n",
    "                l2_error = scores_delta.dot(self.W3.T)\n",
    "                l2_delta = l2_error * self.leaky_relu_der(l2)\n",
    "                l1_error = l2_delta.dot(self.W2.T)\n",
    "                l1_delta = l1_error * self.leaky_relu_der(l1)\n",
    "            ##############################################\n",
    "            \n",
    "            #REGULARIZATION#######################\n",
    "            scores_delta = self.reg * scores_delta\n",
    "            l2_delta = self.reg * l2_delta\n",
    "            l1_delta = self.reg * l1_delta\n",
    "            ######################################\n",
    "            \n",
    "            if self.update == 'SGD':\n",
    "                self.W1 += X.T.dot(l1_delta) * self.learning_rate\n",
    "                self.b1 += np.sum(np.sum(l1_delta, axis=0, keepdims=True) * self.learning_rate, axis=1)\n",
    "                self.W2 += l1.T.dot(l2_delta) * self.learning_rate\n",
    "                self.b2 += np.sum(np.sum(l2_delta, axis=0, keepdims=True) * self.learning_rate, axis=1)\n",
    "                self.W3 += l2.T.dot(scores_delta) * self.learning_rate\n",
    "                self.b3 += np.sum(np.sum(scores_delta, axis=0, keepdims=True) * self.learning_rate, axis=1)\n",
    "            \n",
    "            elif self.update == 'momentum':\n",
    "                vW1 = self.momentum * vW1 *  X.T.dot(l1_delta) * self.learning_rate\n",
    "                self.W1 += vW1\n",
    "                vb1 = self.momentum * vb1 * np.sum(np.sum(l1_delta, axis=0, keepdims=True) * self.learning_rate, axis=1)\n",
    "                self.b1 += vb1\n",
    "                vW2 = self.momentum * vW2 *  l1.T.dot(l2_delta) * self.learning_rate\n",
    "                self.W2 += vW2\n",
    "                vb2 = self.momentum * vb2 * np.sum(np.sum(l2_delta, axis=0, keepdims=True) * self.learning_rate, axis=1)\n",
    "                self.b2 += vb2\n",
    "                vW3 = self.momentum * vW3 *  l2.T.dot(scores_delta) * self.learning_rate\n",
    "                self.W3 += vW3\n",
    "                vb3 = self.momentum * vb3 * np.sum(np.sum(scores_delta, axis=0, keepdims=True) * self.learning_rate, axis=1)\n",
    "                self.b3 += vb3\n",
    "                \n",
    "        return loss_history\n",
    "    ######################################################################################\n",
    "    \n",
    "    #FORWARD PASS#########################################################################\n",
    "    #INPUT: X -  data to be processed through neural net\n",
    "    # \n",
    "    #OUTPUT: results per layer and SCORES as a final output from the network\n",
    "    #NOTE: This function needs to be canged depends on just number of layer\n",
    "    def forward_prop(self, X):\n",
    "        if self.dropout == 0:\n",
    "            if self.activation == 'relu':\n",
    "                l1 = self.relu(np.dot(X, self.W1) + self.b1)\n",
    "                l2 = self.relu(np.dot(l1, self.W2) + self.b2)\n",
    "                yHat = self.sigmoid(np.dot(l2, self.W3) + self.b3)\n",
    "\n",
    "            elif self.activation == 'sigmoid':\n",
    "                l1 = self.sigmoid(np.dot(X, self.W1) + self.b1)\n",
    "                l2 = self.sigmoid(np.dot(l1, self.W2) + self.b2)\n",
    "                yHat = self.sigmoid(np.dot(l2, self.W3) + self.b3)\n",
    "\n",
    "            elif self.activation == 'tanh':\n",
    "                l1 = self.tanh(np.dot(X, self.W1) + self.b1)\n",
    "                l2 = self.tanh(np.dot(l1, self.W2) + self.b2)\n",
    "                yHat = self.sigmoid(np.dot(l2, self.W3) + self.b3)\n",
    "\n",
    "            elif self.activation == 'leaky_relu':\n",
    "                l1 = self.leaky_relu(np.dot(X, self.W1) + self.b1)\n",
    "                l2 = self.leaky_relu(np.dot(l1, self.W2) + self.b2)\n",
    "                yHat = self.sigmoid(np.dot(l2, self.W3) + self.b3)\n",
    "        else:\n",
    "            if self.activation == 'relu':\n",
    "                l1 = self.relu(np.dot(X, self.W1) + self.b1)\n",
    "                mask1 = np.random.randn(l1.shape[0], l1.shape[1]) < self.dropout\n",
    "                l1 *= mask1\n",
    "                l2 = self.relu(np.dot(l1, self.W2) + self.b2)\n",
    "                mask2 = np.random.randn(l2.shape[0], l2.shape[1]) < self.dropout\n",
    "                l2 *= mask2\n",
    "                yHat = self.sigmoid(np.dot(l2, self.W3) + self.b3)\n",
    "\n",
    "            elif self.activation == 'sigmoid':\n",
    "                l1 = self.sigmoid(np.dot(X, self.W1) + self.b1)\n",
    "                mask1 = np.random.randn(l1.shape[0], l1.shape[1]) < self.dropout\n",
    "                l1 *= mask1\n",
    "                l2 = self.sigmoid(np.dot(l1, self.W2) + self.b2)\n",
    "                mask2 = np.random.randn(l2.shape[0], l2.shape[1]) < self.dropout\n",
    "                l2 *= mask2\n",
    "                yHat = self.sigmoid(np.dot(l2, self.W3) + self.b3)\n",
    "\n",
    "            elif self.activation == 'tanh':\n",
    "                l1 = self.tanh(np.dot(X, self.W1) + self.b1)\n",
    "                mask1 = np.random.randn(l1.shape[0], l1.shape[1]) < self.dropout\n",
    "                l1 *= mask1\n",
    "                l2 = self.tanh(np.dot(l1, self.W2) + self.b2)\n",
    "                mask2 = np.random.randn(l2.shape[0], l2.shape[1]) < self.dropout\n",
    "                l2 *= mask2\n",
    "                yHat = self.sigmoid(np.dot(l2, self.W3) + self.b3)\n",
    "\n",
    "            elif self.activation == 'leaky_relu':\n",
    "                l1 = self.leaky_relu(np.dot(X, self.W1) + self.b1)\n",
    "                mask1 = np.random.randn(l1.shape[0], l1.shape[1]) < self.dropout\n",
    "                l1 *= mask1\n",
    "                l2 = self.leaky_relu(np.dot(l1, self.W2) + self.b2)\n",
    "                mask2 = np.random.randn(l2.shape[0], l2.shape[1]) < self.dropout\n",
    "                l2 *= mask2\n",
    "                yHat = self.sigmoid(np.dot(l2, self.W3) + self.b3)\n",
    "            \n",
    "        return l1, l2, yHat\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    #PREDICT##############################################################################\n",
    "    #INPUT X - test set to classifie\n",
    "    #\n",
    "    #OUTPUT pred - already converted values to binary classes (0, 1)\n",
    "    def predict(self, X):\n",
    "        l1, l2, scores = self.forward_prop(X)\n",
    "        pred = []\n",
    "        for i in range(len(scores)):\n",
    "            if(scores[i] > 0.5):\n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(0)\n",
    "        return pred\n",
    "    \n",
    "    #INPUT X - test set to classifie\n",
    "    #\n",
    "    #OUTPUT pred - predicted class for each sample in X (input data)\n",
    "    def predict_multi_class(self, X):\n",
    "        l1, l2, scores = self.forward_prop(X)\n",
    "        pred = np.argmax(scores, axis=1)\n",
    "        return pred\n",
    "    ######################################################################################  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Data preprocessing\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_pred):\n",
    "    correct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        helper_int = 0\n",
    "            \n",
    "        if y_pred[i] == y_test[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    return correct/len(y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoche:  0 Loss:  0.595836637839\n",
      "Epoche:  1000 Loss:  0.208205836065\n",
      "Epoche:  2000 Loss:  0.207884224832\n",
      "Epoche:  3000 Loss:  0.207477644925\n",
      "Epoche:  4000 Loss:  0.208052289506\n",
      "Epoche:  5000 Loss:  0.212718586657\n",
      "Epoche:  6000 Loss:  0.216028491571\n",
      "Epoche:  7000 Loss:  0.217495698232\n",
      "Epoche:  8000 Loss:  0.213151012731\n",
      "Epoche:  9000 Loss:  0.20374611758\n",
      "Epoche:  10000 Loss:  0.198143888681\n"
     ]
    }
   ],
   "source": [
    "#default settings\n",
    "nn = NeuralNetwork(verbose=True)\n",
    "loss1 = nn.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoche:  0 Loss:  0.490679516164\n",
      "Epoche:  1000 Loss:  0.204902573533\n",
      "Epoche:  2000 Loss:  0.201548486281\n",
      "Epoche:  3000 Loss:  0.201841368539\n",
      "Epoche:  4000 Loss:  0.200961441175\n",
      "Epoche:  5000 Loss:  0.19965966164\n",
      "Epoche:  6000 Loss:  0.199381840787\n",
      "Epoche:  7000 Loss:  0.198946531541\n",
      "Epoche:  8000 Loss:  0.198995229972\n",
      "Epoche:  9000 Loss:  0.199282166436\n",
      "Epoche:  10000 Loss:  0.199131238537\n"
     ]
    }
   ],
   "source": [
    "nn1 = NeuralNetwork(init='xavier', activation='leaky_relu', update='SGD', verbose=True, momentum=0.9, dropout=0)\n",
    "loss2 = nn1.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoche:  0 Loss:  0.511211247354\n",
      "Epoche:  1000 Loss:  0.187407901653\n",
      "Epoche:  2000 Loss:  0.187275073958\n",
      "Epoche:  3000 Loss:  0.18764463607\n",
      "Epoche:  4000 Loss:  0.185502331743\n",
      "Epoche:  5000 Loss:  0.183852519978\n",
      "Epoche:  6000 Loss:  0.182617644608\n",
      "Epoche:  7000 Loss:  0.18110142402\n",
      "Epoche:  8000 Loss:  0.180950792719\n",
      "Epoche:  9000 Loss:  0.180059783927\n",
      "Epoche:  10000 Loss:  0.180367211002\n"
     ]
    }
   ],
   "source": [
    "nn2 = NeuralNetwork(init='xavier', activation='sigmoid', update='SGD', verbose=True, momentum=0.9, dropout=0.5)\n",
    "loss3 = nn1.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAKaCAYAAADWNnMTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8H9azd3+J1+sWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116018097f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss3, label='Default settigs')\n",
    "plt.plot(loss2, c='r', label='leaky_relu')\n",
    "plt.plot(loss3, c='g', label='sigmoid + dropout')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.24 %\n",
      "85.52 %\n"
     ]
    }
   ],
   "source": [
    "predNN = nn.predict(X_test)\n",
    "predNN1 = nn1.predict(X_test)\n",
    "print(accuracy(predNN, y_test),'%')\n",
    "print(accuracy(predNN1, y_test),'%')\n",
    "#Wierd error in 3rd NN prediction process"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
